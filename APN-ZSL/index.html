<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
          content="Attribute Prototype Network for Zero-Shot Learning">
    <meta name="author" content="Wenjia Xu,
                                Yongqin Xian,
				 Jiuniu Wang,
                                Zeynep Akata,
				 Bernt Schiele">

    <title>Attribute Prototype Network for Zero-Shot Learning</title>
    <!-- Bootstrap core CSS -->
    <!--link href="bootstrap.min.css" rel="stylesheet"-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
          integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="offcanvas.css" rel="stylesheet">
    <!--    <link rel="icon" href="img/favicon.gif" type="image/gif">-->
</head>

<body>
<div class="jumbotron jumbotron-fluid">
    <div class="container"></div>
    <h2>Attribute Prototype Network for Zero-Shot Learning</h2>
<!--            <p class="abstract">An interpretable, data-efficient, and scalable neural scene representation.</p>-->
    <hr>
    <p class="authors">
        <a > Wenjia Xu</a>,
        <a >Yongqin Xian</a>,
	    <a >Jiuniu Wang</a>,
        <a >Zeynep Akata</a>,
	    <a >Bernt Schiele</a>,
        
    </p>
    <div class="btn-group" role="group" aria-label="Top menu">
        <a class="btn btn-primary">Paper</a>
<!-- 	<a href="https://arxiv.org/abs/2007.06877" class="btn btn-primary">Paper</a> -->

        <a href="https://github.com/wenjiaXu/APN-ZSL" class="btn btn-primary">Code</a>
    </div>
</div>

<div class="container">
	<h2>Introduction</h2>
    <div class="section">
<!--         <div class="vcontainer">
            <iframe class='video' src="https://www.youtube.com/embed/H7so-k0YOz4" frameborder="0"
                    allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen></iframe>
        </div> -->
        <hr>
        <p>
            From the beginning of zero-shot learning research, visual attributes have been shown to play an important role. 
	In order to better transfer attribute-based knowledge from known to unknown classes, 
	we argue that an image representation with integrated attribute localization ability would be beneficial for zero-shot learning.
	To this end, we propose a novel zero-shot representation learning framework that jointly learns discriminative global and local features using only class-level attributes. 
	While a visual-semantic embedding layer learns global features, local features are learned through an attribute prototype network that simultaneously regresses and decorrelates attributes from intermediate features.
         We show that our locality augmented image representations achieve a new state-of-the-art on three zero-shot learning benchmarks. As an additional benefit, 
	our model points to the visual evidence of the attributes in an image, e.g. for the CUB dataset, confirming the improved attribute localization ability of our image representation.
	</p>
    </div>
    
    <div class="section">
        <h2>Quantitative Results</h2>
        <hr>
        <p>
            We next show quantitative results for Zero-Shot Learning.
        </p>
	<div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <img src="images/zsl.png" style="width:100%">
            </div> 
        </div>
    </div>
	
    <div class="section">
        <h2>Qualitative Results</h2>
        <hr>
        <p>
            We next show qualitative results for localizing attributes and body parts.
        </p>
	<div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <img src="images/Q1.png" style="width:100%">
            </div> 
        </div>
	<div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <img src="images/Q2.png" style="width:100%">
            </div> 
        </div>
    </div>

   
<!--     <div class="section">
        <h2>Paper</h2>
        <hr>
        <div>
<!--             <div class="list-group">
                <a href="https://arxiv.org/abs/2006.09661"
                   class="list-group-item">
                    <img src="img/paper_thumbnail.png" style="width:100%; margin-right:-20px; margin-top:-10px;">
                </a>
            </div> -->
        </div>
    </div>
 -->
<!--     <div class="section">
        <h2>Bibtex</h2>
        <hr>
        <div class="bibtexsection">
<!--             @inproceedings{sitzmann2019siren,
                author = {Sitzmann, Vincent
                          and Martel, Julien N.P.
                          and Bergman, Alexander W.
                          and Lindell, David B.
                          and Wetzstein, Gordon},
                title = {Implicit Neural Representations
                          with Periodic Activation Functions},
                booktitle = {arXiv},
                year={2020}
            } -->
        </div>
    </div> -->

    <hr>

    <footer>
        <p>Send feedback and questions to <a href="wenjiaXu.github.io">Wenjia Xu</a></p>
    </footer>
</div>


<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
        integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
        crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"
        integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI"
        crossorigin="anonymous"></script>

</body>
</html>
